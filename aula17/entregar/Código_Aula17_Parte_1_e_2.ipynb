{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Atividade da Aula\n",
    "\n",
    "- **Aluno:** Augusto Mathias Adams\n",
    "\n",
    "#### Parte 1\n",
    "\n",
    "**Rode todo o código. Responda às questões nele contidas e complete-o, se necessário. Por que resultados ligeiramente diferentes são obtidos cada vez que o código ́e rodado?**\n",
    "\n",
    "Feito. \n",
    "\n",
    " - ***Resposta à questão:*** O TensorFlow inicializa os pesos das camadas de forma aleatória para evitar tendências no treinamento, e os otimizadores, como o mini-batch gradient descent, também introduzem aleatoriedade ao selecionar lotes de treinamento por meio de amostragem estocástica. Assim, sem a definição de uma semente para a geração dos pesos e a seleção dos lotes, é improvável que dois treinamentos distintos resultem na mesma acurácia. Contudo, essa variação pode ser mitigada ao especificar uma semente aleatória, o que garante a reprodutibilidade dos resultados. Até a versão 2.10 do *tensorflow*, era possível fixar a semente aleatória para a inicialização dos pesos e para amostragem estocástica através da biblioteca *numpy* ou informar a semente de forma explícita no *tensorflow*. No entanto, a partir da versão 2.10 é necessário informar um inicializador com a semente aleatória anexada para garantir reprodutibilidade. Usarei esta estratégia na segunda parte da tarefa.\n",
    "\n",
    "#### Parte 2\n",
    "1. **Testando diferentes valores para o número de camadas da rede e para o número de neurônios em cada camada, busque uma topologia de rede neural que resulta numa taxa de acerto para os dados de validacão $> 80\\%$.**\n",
    " - ***Estratégia***: O código de testes é projetado para realizar uma análise exaustiva do espaço de hiperparâmetros e identificar aquelas configurações que melhoram o desempenho da rede neural em termos de acurácia no conjunto de teste, semelhante a um *Grid Search* empregado por bibliotecas ou pacotes como *SKLearn* e outros. Para efeitos de clareza e simplicidade, supus que os neurônios se distribuem de forma linear entre as camadas, sendo a rede neural apresentada ao longo da explicação da tarefa a inspiração para tal suposição.\n",
    "    - ***Épocas Testadas***: 50, 100, 150, 200, 250, 300\n",
    "    - ***Neurônios da Primeira Camada***: 10, 20, 30, 40, 50\n",
    "    - ***Camadas Utilizadas***: 2, 3, 4, 5\n",
    " - ***Resultados***:\n",
    "   - **Arquiteturas selecionadas pelo *Grid Search***\n",
    "\n",
    "|   Teste |   Épocas |   Camadas |   Neurônios (1. C) |   $Acc_{treino}\\%$ |   $Acc_{teste}\\%$ |\n",
    "|--------:|---------:|----------:|-------------------:|-------------------:|------------------:|\n",
    "|      14 |       50 |         3 |                 40 |            98.1019 |           82.2083 |\n",
    "|      34 |      100 |         3 |                 40 |            99.7407 |           83.2917 |\n",
    "|      40 |      100 |         5 |                 50 |            99.6667 |           80.5    |\n",
    "|      42 |      150 |         3 |                 10 |            97.5926 |           81.125  |\n",
    "|      54 |      150 |         3 |                 40 |            99.7778 |           82.5833 |\n",
    "|      60 |      150 |         5 |                 50 |            99.7685 |           80.0625 |\n",
    "|      62 |      200 |         3 |                 10 |            97.6111 |           80.2917 |\n",
    "|      74 |      200 |         3 |                 40 |            99.8056 |           81.0625 |\n",
    "|      82 |      250 |         3 |                 10 |            98.2315 |           80.3125 |\n",
    "|     100 |      250 |         5 |                 50 |            99.8981 |           81.3333 |\n",
    "|     120 |      300 |         5 |                 50 |            99.8981 |           82.3958 |\n",
    "   - **Todas as Arquiteturas Testadas**\n",
    "\n",
    "|   Teste |   Épocas |   Camadas |   Neurônios (1. C) |   $Acc_{treino}\\%$ |   $Acc_{teste}\\%$ |\n",
    "|--------:|---------:|----------:|-------------------:|-------------------:|------------------:|\n",
    "|       1 |       50 |         2 |                 10 |            94.1111 |           68.4375 |\n",
    "|       2 |       50 |         3 |                 10 |            96.2315 |           74.4583 |\n",
    "|       3 |       50 |         4 |                 10 |            94.1019 |           72.9792 |\n",
    "|       4 |       50 |         5 |                 10 |            97.5185 |           70.9167 |\n",
    "|       5 |       50 |         2 |                 20 |            95.8796 |           72.7083 |\n",
    "|       6 |       50 |         3 |                 20 |            96.6481 |           74.0625 |\n",
    "|       7 |       50 |         4 |                 20 |            98.0556 |           74.7708 |\n",
    "|       8 |       50 |         5 |                 20 |            98.1667 |           76.2917 |\n",
    "|       9 |       50 |         2 |                 30 |            96.5648 |           74.0208 |\n",
    "|      10 |       50 |         3 |                 30 |            97.713  |           75.4375 |\n",
    "|      11 |       50 |         4 |                 30 |            97.7685 |           75.3333 |\n",
    "|      12 |       50 |         5 |                 30 |            98.2963 |           75.1458 |\n",
    "|      13 |       50 |         2 |                 40 |            96.3056 |           74.7292 |\n",
    "|      14 |       50 |         3 |                 40 |            98.1019 |           82.2083 |\n",
    "|      15 |       50 |         4 |                 40 |            98.1574 |           76.6875 |\n",
    "|      16 |       50 |         5 |                 40 |            99.5463 |           73.5208 |\n",
    "|      17 |       50 |         2 |                 50 |            96.787  |           75      |\n",
    "|      18 |       50 |         3 |                 50 |            97.7778 |           77.6042 |\n",
    "|      19 |       50 |         4 |                 50 |            98.6204 |           78.1458 |\n",
    "|      20 |       50 |         5 |                 50 |            99.1111 |           78.9375 |\n",
    "|      21 |      100 |         2 |                 10 |            95.7963 |           70.9375 |\n",
    "|      22 |      100 |         3 |                 10 |            97.2407 |           77.9167 |\n",
    "|      23 |      100 |         4 |                 10 |            97.2407 |           73.6875 |\n",
    "|      24 |      100 |         5 |                 10 |            98.0093 |           68.2083 |\n",
    "|      25 |      100 |         2 |                 20 |            97.0278 |           74.4792 |\n",
    "|      26 |      100 |         3 |                 20 |            98.5648 |           75.875  |\n",
    "|      27 |      100 |         4 |                 20 |            99.4444 |           74.7292 |\n",
    "|      28 |      100 |         5 |                 20 |            99.6019 |           77.4792 |\n",
    "|      29 |      100 |         2 |                 30 |            97.3241 |           74.0417 |\n",
    "|      30 |      100 |         3 |                 30 |            99.3333 |           76.5    |\n",
    "|      31 |      100 |         4 |                 30 |            99.6852 |           76      |\n",
    "|      32 |      100 |         5 |                 30 |            99.6944 |           75.8125 |\n",
    "|      33 |      100 |         2 |                 40 |            97.7407 |           76.0417 |\n",
    "|      34 |      100 |         3 |                 40 |            99.7407 |           83.2917 |\n",
    "|      35 |      100 |         4 |                 40 |            99.8426 |           76.5833 |\n",
    "|      36 |      100 |         5 |                 40 |            99.4722 |           74.375  |\n",
    "|      37 |      100 |         2 |                 50 |            97.5556 |           75.0625 |\n",
    "|      38 |      100 |         3 |                 50 |            99.787  |           78.1042 |\n",
    "|      39 |      100 |         4 |                 50 |            99.7685 |           77.6667 |\n",
    "|      40 |      100 |         5 |                 50 |            99.6667 |           80.5    |\n",
    "|      41 |      150 |         2 |                 10 |            96.3704 |           70.4792 |\n",
    "|      42 |      150 |         3 |                 10 |            97.5926 |           81.125  |\n",
    "|      43 |      150 |         4 |                 10 |            97.6944 |           73.9583 |\n",
    "|      44 |      150 |         5 |                 10 |            98.5648 |           67.4583 |\n",
    "|      45 |      150 |         2 |                 20 |            97.3519 |           74.7708 |\n",
    "|      46 |      150 |         3 |                 20 |            99.1852 |           76.8333 |\n",
    "|      47 |      150 |         4 |                 20 |            99.7963 |           74.9167 |\n",
    "|      48 |      150 |         5 |                 20 |            99.4259 |           78.6875 |\n",
    "|      49 |      150 |         2 |                 30 |            97.9907 |           73.6875 |\n",
    "|      50 |      150 |         3 |                 30 |            99.787  |           77.0208 |\n",
    "|      51 |      150 |         4 |                 30 |            99.8519 |           75.75   |\n",
    "|      52 |      150 |         5 |                 30 |            99.6574 |           76.1458 |\n",
    "|      53 |      150 |         2 |                 40 |            98.3241 |           77.5208 |\n",
    "|      54 |      150 |         3 |                 40 |            99.7778 |           82.5833 |\n",
    "|      55 |      150 |         4 |                 40 |            99.6111 |           76.9583 |\n",
    "|      56 |      150 |         5 |                 40 |            99.7037 |           74.4792 |\n",
    "|      57 |      150 |         2 |                 50 |            98.4815 |           76.1458 |\n",
    "|      58 |      150 |         3 |                 50 |            99.8611 |           78.1875 |\n",
    "|      59 |      150 |         4 |                 50 |            99.8981 |           77.6458 |\n",
    "|      60 |      150 |         5 |                 50 |            99.7685 |           80.0625 |\n",
    "|      61 |      200 |         2 |                 10 |            96.4167 |           70.4167 |\n",
    "|      62 |      200 |         3 |                 10 |            97.6111 |           80.2917 |\n",
    "|      63 |      200 |         4 |                 10 |            98      |           74.125  |\n",
    "|      64 |      200 |         5 |                 10 |            98.6296 |           68.3333 |\n",
    "|      65 |      200 |         2 |                 20 |            97.787  |           75.1667 |\n",
    "|      66 |      200 |         3 |                 20 |            99.3426 |           77.5    |\n",
    "|      67 |      200 |         4 |                 20 |            99.8704 |           73.7917 |\n",
    "|      68 |      200 |         5 |                 20 |            99.6944 |           78.4792 |\n",
    "|      69 |      200 |         2 |                 30 |            98.2407 |           74.125  |\n",
    "|      70 |      200 |         3 |                 30 |            99.75   |           75.5208 |\n",
    "|      71 |      200 |         4 |                 30 |            99.5278 |           75.875  |\n",
    "|      72 |      200 |         5 |                 30 |            99.6111 |           76.5625 |\n",
    "|      73 |      200 |         2 |                 40 |            98.7778 |           77.875  |\n",
    "|      74 |      200 |         3 |                 40 |            99.8056 |           81.0625 |\n",
    "|      75 |      200 |         4 |                 40 |            99.8889 |           76.3542 |\n",
    "|      76 |      200 |         5 |                 40 |            99.8704 |           75.8958 |\n",
    "|      77 |      200 |         2 |                 50 |            99.0648 |           76.6667 |\n",
    "|      78 |      200 |         3 |                 50 |            99.8519 |           78.4167 |\n",
    "|      79 |      200 |         4 |                 50 |            99.8981 |           77.0625 |\n",
    "|      80 |      200 |         5 |                 50 |            99.8981 |           79.1042 |\n",
    "|      81 |      250 |         2 |                 10 |            96.537  |           70.8333 |\n",
    "|      82 |      250 |         3 |                 10 |            98.2315 |           80.3125 |\n",
    "|      83 |      250 |         4 |                 10 |            98.2963 |           73.5208 |\n",
    "|      84 |      250 |         5 |                 10 |            99.4815 |           67.6667 |\n",
    "|      85 |      250 |         2 |                 20 |            98.0185 |           75.6875 |\n",
    "|      86 |      250 |         3 |                 20 |            99.6667 |           76.9792 |\n",
    "|      87 |      250 |         4 |                 20 |            99.8519 |           73.1875 |\n",
    "|      88 |      250 |         5 |                 20 |            99.5648 |           77.8958 |\n",
    "|      89 |      250 |         2 |                 30 |            98.4722 |           75.2083 |\n",
    "|      90 |      250 |         3 |                 30 |            99.287  |           73.9167 |\n",
    "|      91 |      250 |         4 |                 30 |            99.7222 |           76.1458 |\n",
    "|      92 |      250 |         5 |                 30 |            99.8796 |           78.0417 |\n",
    "|      93 |      250 |         2 |                 40 |            99.1759 |           78.5    |\n",
    "|      94 |      250 |         3 |                 40 |            99.8148 |           78.8333 |\n",
    "|      95 |      250 |         4 |                 40 |            99.7222 |           75.6042 |\n",
    "|      96 |      250 |         5 |                 40 |            99.8611 |           75.6458 |\n",
    "|      97 |      250 |         2 |                 50 |            99.2037 |           77.0625 |\n",
    "|      98 |      250 |         3 |                 50 |            99.2963 |           77.0208 |\n",
    "|      99 |      250 |         4 |                 50 |            99.8796 |           76.8542 |\n",
    "|     100 |      250 |         5 |                 50 |            99.8981 |           81.3333 |\n",
    "|     101 |      300 |         2 |                 10 |            96.9722 |           70.625  |\n",
    "|     102 |      300 |         3 |                 10 |            98.75   |           79.6667 |\n",
    "|     103 |      300 |         4 |                 10 |            98.713  |           73.9375 |\n",
    "|     104 |      300 |         5 |                 10 |            99.3148 |           66.25   |\n",
    "|     105 |      300 |         2 |                 20 |            98.5185 |           76      |\n",
    "|     106 |      300 |         3 |                 20 |            99.6481 |           76.9167 |\n",
    "|     107 |      300 |         4 |                 20 |            99.7593 |           75.0417 |\n",
    "|     108 |      300 |         5 |                 20 |            99.8796 |           79.2083 |\n",
    "|     109 |      300 |         2 |                 30 |            98.8241 |           75.7917 |\n",
    "|     110 |      300 |         3 |                 30 |            99.2778 |           74.9167 |\n",
    "|     111 |      300 |         4 |                 30 |            99.8611 |           75.9792 |\n",
    "|     112 |      300 |         5 |                 30 |            99.8981 |           78.2083 |\n",
    "|     113 |      300 |         2 |                 40 |            99.5741 |           78.8542 |\n",
    "|     114 |      300 |         3 |                 40 |            99.8611 |           78.6875 |\n",
    "|     115 |      300 |         4 |                 40 |            99.8889 |           75.8542 |\n",
    "|     116 |      300 |         5 |                 40 |            99.8796 |           75.3333 |\n",
    "|     117 |      300 |         2 |                 50 |            99.787  |           77.7917 |\n",
    "|     118 |      300 |         3 |                 50 |            99.8981 |           78.0625 |\n",
    "|     119 |      300 |         4 |                 50 |            99.8981 |           77.3542 |\n",
    "|     120 |      300 |         5 |                 50 |            99.8981 |           82.3958 |\n",
    "\n",
    "- **Neurônios Por Camada das Redes Neurais Selecionadas**\n",
    "\n",
    "   - Épocas = 50,  Camadas = 3, Neurônios da primeira camada = 40, Neurônios Por Camada = [40, 20, 1]\n",
    "   - Épocas = 100,  Camadas = 3, Neurônios da primeira camada = 40, Neurônios Por Camada = [40, 20, 1]\n",
    "   - Épocas = 100,  Camadas = 5, Neurônios da primeira camada = 50, Neurônios Por Camada = [50, 37, 25, 13, 1]\n",
    "   - Épocas = 150,  Camadas = 3, Neurônios da primeira camada = 10, Neurônios Por Camada = [10, 5, 1]\n",
    "   - Épocas = 150,  Camadas = 3, Neurônios da primeira camada = 40, Neurônios Por Camada = [40, 20, 1]\n",
    "   - Épocas = 150,  Camadas = 5, Neurônios da primeira camada = 50, Neurônios Por Camada = [50, 37, 25, 13, 1]\n",
    "   - Épocas = 200,  Camadas = 3, Neurônios da primeira camada = 10, Neurônios Por Camada = [10, 5, 1]\n",
    "   - Épocas = 200,  Camadas = 3, Neurônios da primeira camada = 40, Neurônios Por Camada = [40, 20, 1]\n",
    "   - Épocas = 250,  Camadas = 3, Neurônios da primeira camada = 10, Neurônios Por Camada = [10, 5, 1]\n",
    "   - Épocas = 250,  Camadas = 5, Neurônios da primeira camada = 50, Neurônios Por Camada = [50, 37, 25, 13, 1]\n",
    "   - Épocas = 300,  Camadas = 5, Neurônios da primeira camada = 50, Neurônios Por Camada = [50, 37, 25, 13, 1]\n",
    "\n",
    "- **Conclusões**: embora haja arquiteturas cuja acurácia de teste seja maior que $80\\%$, a diferença entre a acurácia de treino e teste não descarta a possibilidade de sobreajuste do modelo ou a possibilidade de problema mal condicionado. Possibilidades de Desenvolvimento Futuro:\n",
    "   - Mitigar o sobreajuste das redes neurais utilizando regularização *L1* (*Ridge*), *L2* (*Lasso*) ou *ElasticNet* (*L1L2*), até mesmo com Camadas *Dropout* entre as camadas *Dense*.\n",
    "   - Uma rápida inspeção dos dados de treinamento demonstrou que existem colunas com valores próximos, possivelmente atuando como tendência na classificação. Uma possibilidade seria efetuar uma análise *PCA* sobre os dados coletados pelas *PMUs*, para aumentar a acurácia e generalização para dados não vistos.\n",
    "   - A engenharia de características não está descartada para melhora do modelo de predição. Contudo, maiores estudos do domínio do problema devem ser efetuados para determinar a transformação necessária dos dados em índices de desempenho.\n",
    "   - Técnicas de *ensemble* ou sistemas votantes seria úteis, caso as alternativas anteriores se demonstrem ineficazes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "udyZSKHUdTbT"
   },
   "source": [
    "# Redes neurais para localizar área sob falta de um sistema elétrico de potência\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ey8D1_6JdTbj",
    "tags": []
   },
   "source": [
    "## Pacotes:\n",
    "\n",
    "Importaremos aqui os seguintes pacotes:\n",
    "- [numpy](https://numpy.org/) é o pacote fundamental para computação científica com Python\n",
    "- [matplotlib](http://matplotlib.org) é uma biblioteca popular para plotar gráficos em Python\n",
    "- [tensorflow](https://www.tensorflow.org/) é uma plataforma popular para Aprendizado de Máquina em Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "CPUJlM4wdTbk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.16.2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# meus imports customizados - segunda atividade\n",
    "import tensorflow.keras.models as t_model\n",
    "import tensorflow.keras.layers as t_layers\n",
    "import seaborn as sns\n",
    "from tabulate import tabulate\n",
    "\n",
    "# os imports da tarefa - não deve causar conflito.\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# O comando '%matplotlib inline' serve para que os gráficos sejam plotados imediatamente após a célula atual\n",
    "\n",
    "import logging\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "tf.autograph.set_verbosity(0)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S2z1UcUidTbn",
    "tags": []
   },
   "source": [
    "\n",
    "### Definição do Problema\n",
    "\n",
    "Nessa atividade de programação, você irá usar uma rede neural para localizar qual área de um determinado sistema elétrico (área 1 ou área 2) encontra-se sob falta (curto-circuito monofásico). Trata-se de um problema de classificação binária.\n",
    "\n",
    "### Conjunto de dados\n",
    "\n",
    "Começaremos essa atividade carregando os dados\n",
    "\n",
    "- O conjunto de dados contém 10800 amostras de treinamento de 308 sinais elétricos do sistema. Cada amostra possui um rótulo que informa se essa amostra se refere a um curto-circuito que ocorreu na área 1 do sistema ou na área 2.  \n",
    "\n",
    "    - Cada amostra de treinamento é um instante de tempo onde 308 sinais elétricos do sistema foram medidos (fasores de tensão e de corrente, frequência de operação, fluxos de potência, etc)\n",
    "    - Isso nos leva à matriz X (10800 x 308), onde cada linha é um exemplo de um instante de tempo onde os 308 sinais elétricos do sistema foram medidos.\n",
    "\n",
    "$$X =\n",
    "\\left(\\begin{array}{cc}\n",
    "--- (x^{(1)}) --- \\\\\n",
    "--- (x^{(2)}) --- \\\\\n",
    "\\vdots \\\\\n",
    "--- (x^{(m=10800)}) ---\n",
    "\\end{array}\\right)$$\n",
    "\n",
    "- O conjunto de dados de treinamento também possui vetor `y` com dimensões 10800 x 1. Ele contém os rótulos corretos para as amostras que estão em `X`\n",
    "    - `y = 0` indica que a falta ocorreu na área `1`, e `y = 1` indica que a falta ocorreu na área `2`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "uSZBoXL_dTbp"
   },
   "outputs": [],
   "source": [
    "# Carregando a matriz de características\n",
    "file = open('X.csv')\n",
    "X    = np.loadtxt(file, delimiter=\",\")\n",
    "# Cada linha denota um instante de tempo onde as PMUs (Phasor Measurement Units) fizeram medições.\n",
    "# Cada coluna denota um sinal elétrico diferente medido pela PMU\n",
    "\n",
    "# Carregando vetor de classes (rótulos) correspondente\n",
    "file = open('y.csv')\n",
    "y    = np.loadtxt(file, delimiter=\",\")\n",
    "y    = y.reshape((-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mERMHAhOdTbq"
   },
   "source": [
    "\n",
    "#### Olhando as variáveis\n",
    "\n",
    "Vamos agora nos familiarizar com o conjunto de dados.\n",
    "- Uma boa forma para começar é dar print de cada variável e ver o que ela contém\n",
    "\n",
    "O código abaixo dá print dos elementos contidos nas variáveis `X` e `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HrXPmfWzdTbr",
    "outputId": "977bc15e-64a8-472c-992a-24fff45882b6",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O primeiro elemento de X é:  [ 6.0000e+01  1.0061e+00 -1.3667e-01  2.9200e+00 -2.8719e+00 -4.8145e-02\n",
      " -1.9173e+00  1.8966e+00  2.0643e-02  3.2000e+00 -3.1487e+00 -5.1262e-02\n",
      "  1.5300e+00 -1.5158e+00 -1.4190e-02  6.0000e+01  1.0258e+00 -1.1119e-01\n",
      "  3.1364e+00  2.2632e+00 -4.7942e+00 -3.1895e+00 -3.0882e-01  2.8930e+00\n",
      " -6.5488e-01  1.8953e-01  9.8029e-01  2.1653e-01  9.9143e-01 -1.7229e+00\n",
      "  3.2900e+00  2.3004e+00 -5.0267e+00 -3.2957e+00 -4.2702e-01  3.1592e+00\n",
      "  3.2300e-01 -4.4606e-01 -4.7245e-01  1.3255e-01 -9.8263e-01  1.4456e+00\n",
      "  6.0000e+01  1.0252e+00 -1.3135e-01  2.0101e+00  2.3683e-01 -2.2469e+00\n",
      " -3.4909e-01  4.0099e-01 -5.1905e-02  2.1067e+00  1.9014e-01 -2.2968e+00\n",
      "  9.3869e-02 -4.4222e-01  3.4836e-01  6.0000e+01  1.0495e+00 -1.8696e-02\n",
      "  1.1696e+00 -5.9836e+00  4.8140e+00  7.4349e-02  5.9050e-01 -6.6485e-01\n",
      "  1.2262e+00 -6.2910e+00  5.0649e+00 -9.9899e-02 -5.0788e-01  6.0778e-01\n",
      "  6.0000e+01  9.9034e-01 -3.4802e-02  6.2969e+00 -5.0571e+00 -1.2398e+00\n",
      " -1.2613e+00  1.3401e+00 -7.8811e-02  6.2800e+00 -5.0549e+00 -1.2251e+00\n",
      "  1.0300e+00 -1.1512e+00  1.2120e-01  6.0000e+01  1.0295e+00 -6.8014e-02\n",
      "  2.5765e+00 -5.7888e+00  3.2123e+00 -1.2873e+00  1.2420e+00  4.5306e-02\n",
      "  2.7400e+00 -6.0439e+00  3.3039e+00  1.1500e+00 -8.8487e-01 -2.6512e-01\n",
      "  6.0000e+01  1.0497e+00  1.2264e-02  4.1238e-01 -6.2083e+00  5.7960e+00\n",
      " -3.8090e-01  1.3562e+00 -9.7533e-01  4.2818e-01 -6.5000e+00  6.0718e+00\n",
      "  4.0487e-01 -1.4997e+00  1.0948e+00  6.0000e+01  1.0448e+00  8.5809e-03\n",
      "  2.3753e+00  3.3866e+00 -5.3476e+00 -4.1430e-01 -7.9020e-01  2.0794e-02\n",
      "  1.9518e-01  5.7422e-01  2.4750e+00  3.5386e+00 -5.5857e+00 -4.2795e-01\n",
      "  8.4600e-01  7.3345e-03 -2.4982e-01 -6.0351e-01  6.0000e+01  1.0315e+00\n",
      " -1.0964e-01  3.0521e+00  3.1633e-01 -3.3684e+00  5.6750e-01 -9.2148e-01\n",
      "  3.5398e-01  3.0860e+00  4.2732e-01 -3.5133e+00 -9.2000e-01  9.1583e-01\n",
      "  4.1738e-03  6.0000e+01  1.0548e+00 -8.0513e-02  2.0775e+00  6.8239e-01\n",
      " -5.1203e+00  2.3605e+00 -6.0608e-01  1.1006e-01 -2.1412e-01  7.1014e-01\n",
      "  2.2400e+00  7.1089e-01 -5.3834e+00  2.4326e+00  4.7200e-01 -1.7103e-01\n",
      "  6.3810e-01 -9.3907e-01  6.0000e+01  1.0475e+00 -1.0137e-01  1.2991e+00\n",
      "  2.4237e+00 -1.3119e+00 -1.7752e+00 -6.3573e-01 -2.8803e-01 -8.9624e-01\n",
      "  3.3725e-01  4.1786e-01  4.2915e-01  1.3900e+00  2.6296e+00 -1.4083e+00\n",
      " -1.9019e+00 -7.0941e-01  1.7000e-01  6.9307e-01 -2.2026e-01 -2.5772e-01\n",
      " -3.8507e-01  6.0000e+01  1.0291e+00 -1.3539e-01  2.5893e+00 -1.9394e-01\n",
      " -2.3954e+00 -1.0744e+00 -7.0653e-02  1.1450e+00  2.8100e+00 -1.9001e-01\n",
      " -2.6200e+00  7.5500e-01  9.8964e-02 -8.5396e-01  6.0000e+01  1.0499e+00\n",
      " -3.7009e-02  1.9504e+00 -3.3163e+00  1.3659e+00 -3.3164e-01 -1.4928e-01\n",
      "  4.8092e-01  2.0600e+00 -3.4762e+00  1.4162e+00  2.7600e-01  2.7946e-01\n",
      " -5.5546e-01  6.0000e+01  1.0503e+00  1.3529e-02  2.7021e+00 -7.8417e+00\n",
      "  1.8204e+00  3.3192e+00 -2.2131e-01 -8.5088e-01  6.6144e-01  4.1075e-01\n",
      "  2.8350e+00 -8.2477e+00  1.9210e+00  3.4918e+00  2.6900e-01  7.8759e-01\n",
      " -6.7008e-01 -3.8651e-01  6.0000e+01  9.9432e-01  7.3000e-02 -6.4025e+00\n",
      "  6.4025e+00  6.3183e-01 -6.3183e-01 -6.3200e+00  6.3200e+00 -1.0956e+00\n",
      "  1.0956e+00  6.0000e+01  1.0104e+00  5.6139e-02 -5.1026e+00  5.1026e+00\n",
      "  1.3522e+00 -1.3522e+00 -5.0800e+00  5.0800e+00 -1.6528e+00  1.6528e+00\n",
      "  6.0000e+01  1.0439e+00  1.0296e-01 -6.3636e+00  6.3636e+00  1.3901e+00\n",
      " -1.3901e+00 -6.5000e+00  6.5000e+00 -2.1064e+00  2.1064e+00  6.0000e+01\n",
      "  1.0528e+00  1.5394e-01 -5.3477e+00  5.3477e+00  1.9519e-01 -1.9519e-01\n",
      " -5.6000e+00  5.6000e+00 -1.0287e+00  1.0287e+00  6.0000e+01  1.0271e+00\n",
      "  4.3344e-02 -5.2483e+00  5.2483e+00 -2.1947e-01  2.1947e-01 -5.4000e+00\n",
      "  5.4000e+00 -2.0640e-03  2.0640e-03  6.0000e+01  1.0175e+00  1.3929e-01\n",
      " -8.0378e+00  8.0378e+00 -8.7215e-01  8.7215e-01 -8.3000e+00  8.3000e+00\n",
      " -2.3212e-01  2.3212e-01]\n"
     ]
    }
   ],
   "source": [
    "print ('O primeiro elemento de X é: ', X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r5Kc7STodTbt",
    "outputId": "e2f09cb6-8d63-4488-8d1c-e80fe356bd61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O primeiro elemento de y é:  0.0    ---> Ou seja, trata-se da amostra de um evento que ocorreu na área 1\n",
      "O elemento 1000 de y é    :  1.0    ---> Ou seja, trata-se da amostra de um evento que ocorreu na área 2\n"
     ]
    }
   ],
   "source": [
    "print ('O primeiro elemento de y é: ', y[0,0], '   ---> Ou seja, trata-se da amostra de um evento que ocorreu na área 1')\n",
    "print ('O elemento 1000 de y é    : ', y[1000,0], '   ---> Ou seja, trata-se da amostra de um evento que ocorreu na área 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4FhTvnSRdTbu"
   },
   "source": [
    "\n",
    "#### Apenas checando as dimensões das nossas variáveis\n",
    "\n",
    "Uma outra forma de nos familiarizarmos com os nossos dados é verificar suas dimensões."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PVW69HsJdTbv",
    "outputId": "4485fe47-3437-4b9d-8ba3-398de85dfd99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O shape de X é: (10800, 308)\n",
      "O shape de y é: (10800, 1)\n"
     ]
    }
   ],
   "source": [
    "print ('O shape de X é: ' + str(X.shape))\n",
    "print ('O shape de y é: ' + str(y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZmKv5f9qc79A"
   },
   "source": [
    "Abaixo Padronizamos os dados usando uma camada de normalização Tensorflow (normalização Z-Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "_shqlFmCc79A"
   },
   "outputs": [],
   "source": [
    "camada_norm = tf.keras.layers.Normalization(axis=-1)\n",
    "camada_norm.adapt(X)  # calcula média e variância\n",
    "X_norm = camada_norm(X) # características normalizadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bmZ7UjhRdTbx"
   },
   "source": [
    "\n",
    "### Representação do modelo\n",
    "\n",
    "- A rede neural que você irá usar deve possuir 3 camadas do tipo `dense` com ativações do tipo relu e linear.\n",
    "  - lembre-se que nossas entradas são os valores dos sinais elétricos medidos em diferentes pontos do sistema\n",
    "  - Uma vez que 308 sinais elétricos foram medidos, temos um total de $308$ características de entrada\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MnA8V6eYdTby"
   },
   "source": [
    "- A rede neural deve ter $10$ unidades na camada 1, $5$ unidades na camada 2 e $1$ unidade de saída na camada 3.\n",
    "\n",
    "    - Lembre-se que as dimensões dos parâmetros de cada camada são conforme a seguir:\n",
    "        - Se a rede possui numa camada com $s_{out}$ unidades e $s_{in}$ entradas, então\n",
    "            - $W$ terá dimensão $s_{in} \\times s_{out}$.\n",
    "            - $b$ será um vetor com $s_{out}$ elementos\n",
    "  \n",
    "    - Portanto, os shapes de `W` e `b` são:\n",
    "        - Camada 1: O shape de `W1` é (308, 10) e o shape de `b1` é (10,)\n",
    "        - Camada 2: O shape de `W2` é (10,5) e o shape de `b2` é (5,)\n",
    "        - Camada 3: O shape de `W3` é (5,1) e o shape de `b3` é (1,)\n",
    "        \n",
    ">**OBS:** O vetor de bias `b` poderia ser representado como uma array 1-D (n,) ou 2-D (n,1). Tensorflow usa uma representação 1-D e iremos manter essa convenção.               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lNS4j5UvdTbz"
   },
   "source": [
    "\n",
    "### Implementação do modelo usando Tensorflow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1pWhBbwbdTb1"
   },
   "source": [
    "Abaixo, usamos as funções [Sequential model](https://keras.io/guides/sequential_model/) e [Dense Layer](https://keras.io/api/layers/core_layers/dense/) do Keras para construir a rede desejada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "c7GlD6mgdTb2"
   },
   "outputs": [],
   "source": [
    "modelo = Sequential(\n",
    "    [\n",
    "        tf.keras.Input(shape=(308,)),    # especificando a dimensão do vetor de entrada (não é obrigatório especificar)\n",
    "        tf.keras.layers.Dense(10, activation=\"relu\", name=\"camada_1\"),\n",
    "        tf.keras.layers.Dense(5, activation=\"relu\", name=\"camada_2\"),\n",
    "        tf.keras.layers.Dense(1, activation=\"sigmoid\", name=\"predicao\")\n",
    "    ], name = \"meu_modelo\"   # Na definição do nome do modelo, não pode haver espaços em branco\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "id": "_3wYdMZWdTb3",
    "outputId": "43bd9b6b-c80b-4b5e-8585-950647321d69"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"meu_modelo\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"meu_modelo\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ camada_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,090</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ camada_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ predicao (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ camada_1 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m3,090\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ camada_2 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │            \u001b[38;5;34m55\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ predicao (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m6\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,151</span> (12.31 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,151\u001b[0m (12.31 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,151</span> (12.31 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,151\u001b[0m (12.31 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelo.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jR2c-2h9dTb6"
   },
   "source": [
    "A contagem de parâmetros acima corresponde ao número de elementos w + b do modelo, conforme detalhado abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GbamcI9-dTb7",
    "outputId": "b875c1f6-204c-4fbf-f1e2-cfc34ded1844"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número param. camada 1 =  3090 , Número param. camada 2 =  55 ,  Número param. camada 3 =  6\n"
     ]
    }
   ],
   "source": [
    "num_params_camada1 = 308 * 10 + 10  # parâmetros W1 + parâmetros b1\n",
    "num_params_camada2 = 10 * 5 + 5   # parâmetros W2 + parâmetros b2\n",
    "num_params_camada3 = 5 * 1 + 1     # parâmetros W3 + parâmetros b3\n",
    "print(\"Número param. camada 1 = \", num_params_camada1, \", Número param. camada 2 = \", num_params_camada2, \",  Número param. camada 3 = \", num_params_camada3 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iWUPkyl9dTb7"
   },
   "source": [
    "Vamos examinar agora com cuidado os pesos para verificar que o Tensorflow produziu as mesmas dimensões que nós havíamos calculado anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "TfucQqgcdTb8"
   },
   "outputs": [],
   "source": [
    "[camada1, camada2, camada3] = modelo.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z6yJVRyNdTb8",
    "outputId": "398681e3-aec5-4ba2-a832-d28b67bae0c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1 shape = (308, 10), b1 shape = (10,)\n",
      "W2 shape = (10, 5), b2 shape = (5,)\n",
      "W3 shape = (5, 1), b3 shape = (1,)\n"
     ]
    }
   ],
   "source": [
    "#### Examinando os shapes dos pesos\n",
    "W1,b1 = camada1.get_weights()\n",
    "W2,b2 = camada2.get_weights()\n",
    "W3,b3 = camada3.get_weights()\n",
    "print(f\"W1 shape = {W1.shape}, b1 shape = {b1.shape}\")\n",
    "print(f\"W2 shape = {W2.shape}, b2 shape = {b2.shape}\")\n",
    "print(f\"W3 shape = {W3.shape}, b3 shape = {b3.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OHv9Z4sFdTb9"
   },
   "source": [
    "O código a seguir define uma função de perda e roda o método do gradiente para ajustar os pesos do modelo aos dados de treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JQ3ACkE1dTb-",
    "outputId": "5ffe4152-26b9-49cf-b7f2-f824abc128d2",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 593us/step - loss: 0.6014\n",
      "Epoch 2/50\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 583us/step - loss: 0.3848\n",
      "Epoch 3/50\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 584us/step - loss: 0.3010\n",
      "Epoch 4/50\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562us/step - loss: 0.2613\n",
      "Epoch 5/50\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568us/step - loss: 0.2418\n",
      "Epoch 6/50\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 577us/step - loss: 0.2235\n",
      "Epoch 7/50\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849us/step - loss: 0.2133\n",
      "Epoch 8/50\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575us/step - loss: 0.2128\n",
      "Epoch 9/50\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 566us/step - loss: 0.1975\n",
      "Epoch 10/50\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565us/step - loss: 0.1933\n",
      "Epoch 11/50\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 631us/step - loss: 0.1853\n",
      "Epoch 12/50\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 571us/step - loss: 0.1817\n",
      "Epoch 13/50\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563us/step - loss: 0.1774\n",
      "Epoch 14/50\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 584us/step - loss: 0.1749\n",
      "Epoch 15/50\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 570us/step - loss: 0.1690\n",
      "Epoch 16/50\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 589us/step - loss: 0.1658\n",
      "Epoch 17/50\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568us/step - loss: 0.1651\n",
      "Epoch 18/50\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 581us/step - loss: 0.1613\n",
      "Epoch 19/50\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573us/step - loss: 0.1576\n",
      "Epoch 20/50\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592us/step - loss: 0.1512\n",
      "Epoch 21/50\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573us/step - loss: 0.1487\n",
      "Epoch 22/50\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580us/step - loss: 0.1446\n",
      "Epoch 23/50\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565us/step - loss: 0.1433\n",
      "Epoch 24/50\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575us/step - loss: 0.1434\n",
      "Epoch 25/50\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573us/step - loss: 0.1378\n",
      "Epoch 26/50\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651us/step - loss: 0.1353\n",
      "Epoch 27/50\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568us/step - loss: 0.1363\n",
      "Epoch 28/50\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 743us/step - loss: 0.1344\n",
      "Epoch 29/50\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585us/step - loss: 0.1318\n",
      "Epoch 30/50\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573us/step - loss: 0.1280\n",
      "Epoch 31/50\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 604us/step - loss: 0.1262\n",
      "Epoch 32/50\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 579us/step - loss: 0.1276\n",
      "Epoch 33/50\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 566us/step - loss: 0.1248\n",
      "Epoch 34/50\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 583us/step - loss: 0.1238\n",
      "Epoch 35/50\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561us/step - loss: 0.1278\n",
      "Epoch 36/50\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 574us/step - loss: 0.1237\n",
      "Epoch 37/50\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560us/step - loss: 0.1201\n",
      "Epoch 38/50\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 554us/step - loss: 0.1178\n",
      "Epoch 39/50\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step - loss: 0.1198\n",
      "Epoch 40/50\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573us/step - loss: 0.1174\n",
      "Epoch 41/50\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 567us/step - loss: 0.1133\n",
      "Epoch 42/50\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564us/step - loss: 0.1153\n",
      "Epoch 43/50\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575us/step - loss: 0.1140\n",
      "Epoch 44/50\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 570us/step - loss: 0.1121\n",
      "Epoch 45/50\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 594us/step - loss: 0.1120\n",
      "Epoch 46/50\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 659us/step - loss: 0.1077\n",
      "Epoch 47/50\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580us/step - loss: 0.1130\n",
      "Epoch 48/50\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 731us/step - loss: 0.1116\n",
      "Epoch 49/50\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 579us/step - loss: 0.1108\n",
      "Epoch 50/50\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575us/step - loss: 0.1087\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x709ced6028c0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo.compile(\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    ")\n",
    "\n",
    "modelo.fit(\n",
    "    X_norm,y,\n",
    "    epochs=50\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "suqnzkuJdTb-"
   },
   "source": [
    "Abaixo calculamos a taxa de acerto para os dados de estimação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a2Z63V6PdTb_",
    "outputId": "71eafec1-9e8d-480b-ff3b-0d4d4d1d5706"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taxa de acerto para os dados de estimação: 96.3333\n"
     ]
    }
   ],
   "source": [
    "Probabilidades  = modelo(X_norm)\n",
    "Yhat            = (Probabilidades.numpy() >= 0.5).astype(int)\n",
    "taxa_acerto_est = np.mean((Yhat==y)*100)\n",
    "print(f\"taxa de acerto para os dados de estimação: {taxa_acerto_est:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hfnczqLFc79F"
   },
   "source": [
    "## Validando nosso modelo de localização de falta usando novos dados de falta\n",
    "\n",
    "\n",
    "Abaixo calculamos a taxa de acerto para um novo conjunto de dados de eventos com 4800 amostras para verificarmos se o nosso modelo consegue acertar em qual área esse evento ocorreu, mesmo que ele não tenha tido acesso a dados desses eventos durante seu treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "afxrxKXGc79F",
    "outputId": "b8d27496-1e18-4617-fccf-bc0e241c82ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taxa de acerto (acurácia) para os dados de validação: 69.92\n"
     ]
    }
   ],
   "source": [
    "# Carregando a matriz de características\n",
    "file = open('X_val.csv')\n",
    "X_val    = np.loadtxt(file, delimiter=\",\")\n",
    "\n",
    "file = open('y_val.csv')\n",
    "y_val    = np.loadtxt(file, delimiter=\",\")\n",
    "y_val    = y_val.reshape((-1,1))\n",
    "\n",
    "# Aplicando a camada de normalização para esses novos dados:\n",
    "X_val_norm  = camada_norm(X_val)\n",
    "\n",
    "Probabilidades  = modelo(X_val_norm)\n",
    "Yhat            = (Probabilidades.numpy() >= 0.5).astype(int)\n",
    "taxa_acerto_val = np.mean((Yhat==y_val.reshape(-1,1))*100)\n",
    "print(f\"taxa de acerto (acurácia) para os dados de validação: {taxa_acerto_val:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GBtk852AdTcQ"
   },
   "source": [
    "\n",
    "### Parabéns!\n",
    "\n",
    "Você construiu e utilizou uma rede neural para classificação binária que é capaz de localizar a área sob falta em um sistema elétrico!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Happy Hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funções de otimização - Evolução Diferencial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "AfAhTMXgc79G"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10800 4800\n",
      "1 => Épocas = 50, Camadas = 2, Neurônios da primeira camada = 10\n",
      "1 => Treino: 94.11, Teste: 68.44\n",
      "2 => Épocas = 50, Camadas = 3, Neurônios da primeira camada = 10\n",
      "2 => Treino: 96.23, Teste: 74.46\n",
      "3 => Épocas = 50, Camadas = 4, Neurônios da primeira camada = 10\n",
      "3 => Treino: 94.10, Teste: 72.98\n",
      "4 => Épocas = 50, Camadas = 5, Neurônios da primeira camada = 10\n",
      "4 => Treino: 97.52, Teste: 70.92\n",
      "5 => Épocas = 50, Camadas = 2, Neurônios da primeira camada = 20\n",
      "5 => Treino: 95.88, Teste: 72.71\n",
      "6 => Épocas = 50, Camadas = 3, Neurônios da primeira camada = 20\n",
      "6 => Treino: 96.65, Teste: 74.06\n",
      "7 => Épocas = 50, Camadas = 4, Neurônios da primeira camada = 20\n",
      "7 => Treino: 98.06, Teste: 74.77\n",
      "8 => Épocas = 50, Camadas = 5, Neurônios da primeira camada = 20\n",
      "8 => Treino: 98.17, Teste: 76.29\n",
      "9 => Épocas = 50, Camadas = 2, Neurônios da primeira camada = 30\n",
      "9 => Treino: 96.56, Teste: 74.02\n",
      "10 => Épocas = 50, Camadas = 3, Neurônios da primeira camada = 30\n",
      "10 => Treino: 97.71, Teste: 75.44\n",
      "11 => Épocas = 50, Camadas = 4, Neurônios da primeira camada = 30\n",
      "11 => Treino: 97.77, Teste: 75.33\n",
      "12 => Épocas = 50, Camadas = 5, Neurônios da primeira camada = 30\n",
      "12 => Treino: 98.30, Teste: 75.15\n",
      "13 => Épocas = 50, Camadas = 2, Neurônios da primeira camada = 40\n",
      "13 => Treino: 96.31, Teste: 74.73\n",
      "14 => Épocas = 50, Camadas = 3, Neurônios da primeira camada = 40\n",
      "14 => Treino: 98.10, Teste: 82.21\n",
      "Escolha do editor => Épocas = 50,  Camadas = 3, Neurônios da primeira camada = 40\n",
      "15 => Épocas = 50, Camadas = 4, Neurônios da primeira camada = 40\n",
      "15 => Treino: 98.16, Teste: 76.69\n",
      "16 => Épocas = 50, Camadas = 5, Neurônios da primeira camada = 40\n",
      "16 => Treino: 99.55, Teste: 73.52\n",
      "17 => Épocas = 50, Camadas = 2, Neurônios da primeira camada = 50\n",
      "17 => Treino: 96.79, Teste: 75.00\n",
      "18 => Épocas = 50, Camadas = 3, Neurônios da primeira camada = 50\n",
      "18 => Treino: 97.78, Teste: 77.60\n",
      "19 => Épocas = 50, Camadas = 4, Neurônios da primeira camada = 50\n",
      "19 => Treino: 98.62, Teste: 78.15\n",
      "20 => Épocas = 50, Camadas = 5, Neurônios da primeira camada = 50\n",
      "20 => Treino: 99.11, Teste: 78.94\n",
      "21 => Épocas = 100, Camadas = 2, Neurônios da primeira camada = 10\n",
      "21 => Treino: 95.80, Teste: 70.94\n",
      "22 => Épocas = 100, Camadas = 3, Neurônios da primeira camada = 10\n",
      "22 => Treino: 97.24, Teste: 77.92\n",
      "23 => Épocas = 100, Camadas = 4, Neurônios da primeira camada = 10\n",
      "23 => Treino: 97.24, Teste: 73.69\n",
      "24 => Épocas = 100, Camadas = 5, Neurônios da primeira camada = 10\n",
      "24 => Treino: 98.01, Teste: 68.21\n",
      "25 => Épocas = 100, Camadas = 2, Neurônios da primeira camada = 20\n",
      "25 => Treino: 97.03, Teste: 74.48\n",
      "26 => Épocas = 100, Camadas = 3, Neurônios da primeira camada = 20\n",
      "26 => Treino: 98.56, Teste: 75.88\n",
      "27 => Épocas = 100, Camadas = 4, Neurônios da primeira camada = 20\n",
      "27 => Treino: 99.44, Teste: 74.73\n",
      "28 => Épocas = 100, Camadas = 5, Neurônios da primeira camada = 20\n",
      "28 => Treino: 99.60, Teste: 77.48\n",
      "29 => Épocas = 100, Camadas = 2, Neurônios da primeira camada = 30\n",
      "29 => Treino: 97.32, Teste: 74.04\n",
      "30 => Épocas = 100, Camadas = 3, Neurônios da primeira camada = 30\n",
      "30 => Treino: 99.33, Teste: 76.50\n",
      "31 => Épocas = 100, Camadas = 4, Neurônios da primeira camada = 30\n",
      "31 => Treino: 99.69, Teste: 76.00\n",
      "32 => Épocas = 100, Camadas = 5, Neurônios da primeira camada = 30\n",
      "32 => Treino: 99.69, Teste: 75.81\n",
      "33 => Épocas = 100, Camadas = 2, Neurônios da primeira camada = 40\n",
      "33 => Treino: 97.74, Teste: 76.04\n",
      "34 => Épocas = 100, Camadas = 3, Neurônios da primeira camada = 40\n",
      "34 => Treino: 99.74, Teste: 83.29\n",
      "Escolha do editor => Épocas = 100,  Camadas = 3, Neurônios da primeira camada = 40\n",
      "35 => Épocas = 100, Camadas = 4, Neurônios da primeira camada = 40\n",
      "35 => Treino: 99.84, Teste: 76.58\n",
      "36 => Épocas = 100, Camadas = 5, Neurônios da primeira camada = 40\n",
      "36 => Treino: 99.47, Teste: 74.38\n",
      "37 => Épocas = 100, Camadas = 2, Neurônios da primeira camada = 50\n",
      "37 => Treino: 97.56, Teste: 75.06\n",
      "38 => Épocas = 100, Camadas = 3, Neurônios da primeira camada = 50\n",
      "38 => Treino: 99.79, Teste: 78.10\n",
      "39 => Épocas = 100, Camadas = 4, Neurônios da primeira camada = 50\n",
      "39 => Treino: 99.77, Teste: 77.67\n",
      "40 => Épocas = 100, Camadas = 5, Neurônios da primeira camada = 50\n",
      "40 => Treino: 99.67, Teste: 80.50\n",
      "Escolha do editor => Épocas = 100,  Camadas = 5, Neurônios da primeira camada = 50\n",
      "41 => Épocas = 150, Camadas = 2, Neurônios da primeira camada = 10\n",
      "41 => Treino: 96.37, Teste: 70.48\n",
      "42 => Épocas = 150, Camadas = 3, Neurônios da primeira camada = 10\n",
      "42 => Treino: 97.59, Teste: 81.12\n",
      "Escolha do editor => Épocas = 150,  Camadas = 3, Neurônios da primeira camada = 10\n",
      "43 => Épocas = 150, Camadas = 4, Neurônios da primeira camada = 10\n",
      "43 => Treino: 97.69, Teste: 73.96\n",
      "44 => Épocas = 150, Camadas = 5, Neurônios da primeira camada = 10\n",
      "44 => Treino: 98.56, Teste: 67.46\n",
      "45 => Épocas = 150, Camadas = 2, Neurônios da primeira camada = 20\n",
      "45 => Treino: 97.35, Teste: 74.77\n",
      "46 => Épocas = 150, Camadas = 3, Neurônios da primeira camada = 20\n",
      "46 => Treino: 99.19, Teste: 76.83\n",
      "47 => Épocas = 150, Camadas = 4, Neurônios da primeira camada = 20\n",
      "47 => Treino: 99.80, Teste: 74.92\n",
      "48 => Épocas = 150, Camadas = 5, Neurônios da primeira camada = 20\n",
      "48 => Treino: 99.43, Teste: 78.69\n",
      "49 => Épocas = 150, Camadas = 2, Neurônios da primeira camada = 30\n",
      "49 => Treino: 97.99, Teste: 73.69\n",
      "50 => Épocas = 150, Camadas = 3, Neurônios da primeira camada = 30\n",
      "50 => Treino: 99.79, Teste: 77.02\n",
      "51 => Épocas = 150, Camadas = 4, Neurônios da primeira camada = 30\n",
      "51 => Treino: 99.85, Teste: 75.75\n",
      "52 => Épocas = 150, Camadas = 5, Neurônios da primeira camada = 30\n",
      "52 => Treino: 99.66, Teste: 76.15\n",
      "53 => Épocas = 150, Camadas = 2, Neurônios da primeira camada = 40\n",
      "53 => Treino: 98.32, Teste: 77.52\n",
      "54 => Épocas = 150, Camadas = 3, Neurônios da primeira camada = 40\n",
      "54 => Treino: 99.78, Teste: 82.58\n",
      "Escolha do editor => Épocas = 150,  Camadas = 3, Neurônios da primeira camada = 40\n",
      "55 => Épocas = 150, Camadas = 4, Neurônios da primeira camada = 40\n",
      "55 => Treino: 99.61, Teste: 76.96\n",
      "56 => Épocas = 150, Camadas = 5, Neurônios da primeira camada = 40\n",
      "56 => Treino: 99.70, Teste: 74.48\n",
      "57 => Épocas = 150, Camadas = 2, Neurônios da primeira camada = 50\n",
      "57 => Treino: 98.48, Teste: 76.15\n",
      "58 => Épocas = 150, Camadas = 3, Neurônios da primeira camada = 50\n",
      "58 => Treino: 99.86, Teste: 78.19\n",
      "59 => Épocas = 150, Camadas = 4, Neurônios da primeira camada = 50\n",
      "59 => Treino: 99.90, Teste: 77.65\n",
      "60 => Épocas = 150, Camadas = 5, Neurônios da primeira camada = 50\n",
      "60 => Treino: 99.77, Teste: 80.06\n",
      "Escolha do editor => Épocas = 150,  Camadas = 5, Neurônios da primeira camada = 50\n",
      "61 => Épocas = 200, Camadas = 2, Neurônios da primeira camada = 10\n",
      "61 => Treino: 96.42, Teste: 70.42\n",
      "62 => Épocas = 200, Camadas = 3, Neurônios da primeira camada = 10\n",
      "62 => Treino: 97.61, Teste: 80.29\n",
      "Escolha do editor => Épocas = 200,  Camadas = 3, Neurônios da primeira camada = 10\n",
      "63 => Épocas = 200, Camadas = 4, Neurônios da primeira camada = 10\n",
      "63 => Treino: 98.00, Teste: 74.12\n",
      "64 => Épocas = 200, Camadas = 5, Neurônios da primeira camada = 10\n",
      "64 => Treino: 98.63, Teste: 68.33\n",
      "65 => Épocas = 200, Camadas = 2, Neurônios da primeira camada = 20\n",
      "65 => Treino: 97.79, Teste: 75.17\n",
      "66 => Épocas = 200, Camadas = 3, Neurônios da primeira camada = 20\n",
      "66 => Treino: 99.34, Teste: 77.50\n",
      "67 => Épocas = 200, Camadas = 4, Neurônios da primeira camada = 20\n",
      "67 => Treino: 99.87, Teste: 73.79\n",
      "68 => Épocas = 200, Camadas = 5, Neurônios da primeira camada = 20\n",
      "68 => Treino: 99.69, Teste: 78.48\n",
      "69 => Épocas = 200, Camadas = 2, Neurônios da primeira camada = 30\n",
      "69 => Treino: 98.24, Teste: 74.12\n",
      "70 => Épocas = 200, Camadas = 3, Neurônios da primeira camada = 30\n",
      "70 => Treino: 99.75, Teste: 75.52\n",
      "71 => Épocas = 200, Camadas = 4, Neurônios da primeira camada = 30\n",
      "71 => Treino: 99.53, Teste: 75.88\n",
      "72 => Épocas = 200, Camadas = 5, Neurônios da primeira camada = 30\n",
      "72 => Treino: 99.61, Teste: 76.56\n",
      "73 => Épocas = 200, Camadas = 2, Neurônios da primeira camada = 40\n",
      "73 => Treino: 98.78, Teste: 77.88\n",
      "74 => Épocas = 200, Camadas = 3, Neurônios da primeira camada = 40\n",
      "74 => Treino: 99.81, Teste: 81.06\n",
      "Escolha do editor => Épocas = 200,  Camadas = 3, Neurônios da primeira camada = 40\n",
      "75 => Épocas = 200, Camadas = 4, Neurônios da primeira camada = 40\n",
      "75 => Treino: 99.89, Teste: 76.35\n",
      "76 => Épocas = 200, Camadas = 5, Neurônios da primeira camada = 40\n",
      "76 => Treino: 99.87, Teste: 75.90\n",
      "77 => Épocas = 200, Camadas = 2, Neurônios da primeira camada = 50\n",
      "77 => Treino: 99.06, Teste: 76.67\n",
      "78 => Épocas = 200, Camadas = 3, Neurônios da primeira camada = 50\n",
      "78 => Treino: 99.85, Teste: 78.42\n",
      "79 => Épocas = 200, Camadas = 4, Neurônios da primeira camada = 50\n",
      "79 => Treino: 99.90, Teste: 77.06\n",
      "80 => Épocas = 200, Camadas = 5, Neurônios da primeira camada = 50\n",
      "80 => Treino: 99.90, Teste: 79.10\n",
      "81 => Épocas = 250, Camadas = 2, Neurônios da primeira camada = 10\n",
      "81 => Treino: 96.54, Teste: 70.83\n",
      "82 => Épocas = 250, Camadas = 3, Neurônios da primeira camada = 10\n",
      "82 => Treino: 98.23, Teste: 80.31\n",
      "Escolha do editor => Épocas = 250,  Camadas = 3, Neurônios da primeira camada = 10\n",
      "83 => Épocas = 250, Camadas = 4, Neurônios da primeira camada = 10\n",
      "83 => Treino: 98.30, Teste: 73.52\n",
      "84 => Épocas = 250, Camadas = 5, Neurônios da primeira camada = 10\n",
      "84 => Treino: 99.48, Teste: 67.67\n",
      "85 => Épocas = 250, Camadas = 2, Neurônios da primeira camada = 20\n",
      "85 => Treino: 98.02, Teste: 75.69\n",
      "86 => Épocas = 250, Camadas = 3, Neurônios da primeira camada = 20\n",
      "86 => Treino: 99.67, Teste: 76.98\n",
      "87 => Épocas = 250, Camadas = 4, Neurônios da primeira camada = 20\n",
      "87 => Treino: 99.85, Teste: 73.19\n",
      "88 => Épocas = 250, Camadas = 5, Neurônios da primeira camada = 20\n",
      "88 => Treino: 99.56, Teste: 77.90\n",
      "89 => Épocas = 250, Camadas = 2, Neurônios da primeira camada = 30\n",
      "89 => Treino: 98.47, Teste: 75.21\n",
      "90 => Épocas = 250, Camadas = 3, Neurônios da primeira camada = 30\n",
      "90 => Treino: 99.29, Teste: 73.92\n",
      "91 => Épocas = 250, Camadas = 4, Neurônios da primeira camada = 30\n",
      "91 => Treino: 99.72, Teste: 76.15\n",
      "92 => Épocas = 250, Camadas = 5, Neurônios da primeira camada = 30\n",
      "92 => Treino: 99.88, Teste: 78.04\n",
      "93 => Épocas = 250, Camadas = 2, Neurônios da primeira camada = 40\n",
      "93 => Treino: 99.18, Teste: 78.50\n",
      "94 => Épocas = 250, Camadas = 3, Neurônios da primeira camada = 40\n",
      "94 => Treino: 99.81, Teste: 78.83\n",
      "95 => Épocas = 250, Camadas = 4, Neurônios da primeira camada = 40\n",
      "95 => Treino: 99.72, Teste: 75.60\n",
      "96 => Épocas = 250, Camadas = 5, Neurônios da primeira camada = 40\n",
      "96 => Treino: 99.86, Teste: 75.65\n",
      "97 => Épocas = 250, Camadas = 2, Neurônios da primeira camada = 50\n",
      "97 => Treino: 99.20, Teste: 77.06\n",
      "98 => Épocas = 250, Camadas = 3, Neurônios da primeira camada = 50\n",
      "98 => Treino: 99.30, Teste: 77.02\n",
      "99 => Épocas = 250, Camadas = 4, Neurônios da primeira camada = 50\n",
      "99 => Treino: 99.88, Teste: 76.85\n",
      "100 => Épocas = 250, Camadas = 5, Neurônios da primeira camada = 50\n",
      "100 => Treino: 99.90, Teste: 81.33\n",
      "Escolha do editor => Épocas = 250,  Camadas = 5, Neurônios da primeira camada = 50\n",
      "101 => Épocas = 300, Camadas = 2, Neurônios da primeira camada = 10\n",
      "101 => Treino: 96.97, Teste: 70.62\n",
      "102 => Épocas = 300, Camadas = 3, Neurônios da primeira camada = 10\n",
      "102 => Treino: 98.75, Teste: 79.67\n",
      "103 => Épocas = 300, Camadas = 4, Neurônios da primeira camada = 10\n",
      "103 => Treino: 98.71, Teste: 73.94\n",
      "104 => Épocas = 300, Camadas = 5, Neurônios da primeira camada = 10\n",
      "104 => Treino: 99.31, Teste: 66.25\n",
      "105 => Épocas = 300, Camadas = 2, Neurônios da primeira camada = 20\n",
      "105 => Treino: 98.52, Teste: 76.00\n",
      "106 => Épocas = 300, Camadas = 3, Neurônios da primeira camada = 20\n",
      "106 => Treino: 99.65, Teste: 76.92\n",
      "107 => Épocas = 300, Camadas = 4, Neurônios da primeira camada = 20\n",
      "107 => Treino: 99.76, Teste: 75.04\n",
      "108 => Épocas = 300, Camadas = 5, Neurônios da primeira camada = 20\n",
      "108 => Treino: 99.88, Teste: 79.21\n",
      "109 => Épocas = 300, Camadas = 2, Neurônios da primeira camada = 30\n",
      "109 => Treino: 98.82, Teste: 75.79\n",
      "110 => Épocas = 300, Camadas = 3, Neurônios da primeira camada = 30\n",
      "110 => Treino: 99.28, Teste: 74.92\n",
      "111 => Épocas = 300, Camadas = 4, Neurônios da primeira camada = 30\n",
      "111 => Treino: 99.86, Teste: 75.98\n",
      "112 => Épocas = 300, Camadas = 5, Neurônios da primeira camada = 30\n",
      "112 => Treino: 99.90, Teste: 78.21\n",
      "113 => Épocas = 300, Camadas = 2, Neurônios da primeira camada = 40\n",
      "113 => Treino: 99.57, Teste: 78.85\n",
      "114 => Épocas = 300, Camadas = 3, Neurônios da primeira camada = 40\n",
      "114 => Treino: 99.86, Teste: 78.69\n",
      "115 => Épocas = 300, Camadas = 4, Neurônios da primeira camada = 40\n",
      "115 => Treino: 99.89, Teste: 75.85\n",
      "116 => Épocas = 300, Camadas = 5, Neurônios da primeira camada = 40\n",
      "116 => Treino: 99.88, Teste: 75.33\n",
      "117 => Épocas = 300, Camadas = 2, Neurônios da primeira camada = 50\n",
      "117 => Treino: 99.79, Teste: 77.79\n",
      "118 => Épocas = 300, Camadas = 3, Neurônios da primeira camada = 50\n",
      "118 => Treino: 99.90, Teste: 78.06\n",
      "119 => Épocas = 300, Camadas = 4, Neurônios da primeira camada = 50\n",
      "119 => Treino: 99.90, Teste: 77.35\n",
      "120 => Épocas = 300, Camadas = 5, Neurônios da primeira camada = 50\n",
      "120 => Treino: 99.90, Teste: 82.40\n",
      "Escolha do editor => Épocas = 300,  Camadas = 5, Neurônios da primeira camada = 50\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from itertools import product\n",
    "\n",
    "def gerar_combinacoes_hiperparametros(ann_epochs, ann_num_neuronios_primeira, ann_num_camadas):\n",
    "    \"\"\"\n",
    "    Gera todas as combinações possíveis de parâmetros para uma grade de pesquisa (grid search).\n",
    "\n",
    "    Args:\n",
    "        ann_epochs (list): Lista de épocas para treinamento da rede neural.\n",
    "        ann_batch_sizes (list): Lista de tamanhos de lote (batch sizes).\n",
    "        ann_num_neuronios_primeira (list): Lista do número de neurônios na primeira camada.\n",
    "        ann_num_camadas (list): Lista do número de camadas na rede neural.\n",
    "\n",
    "    Returns:\n",
    "        list: Uma lista contendo todas as combinações possíveis de parâmetros.\n",
    "    \"\"\"\n",
    "    combinacoes = list(product(ann_epochs, ann_num_neuronios_primeira, ann_num_camadas))\n",
    "    \n",
    "    return combinacoes\n",
    "\n",
    "\n",
    "def calcular_neuronios(num_neuronios_primeira, \n",
    "                       num_neuronios_ultima, \n",
    "                       num_camadas):\n",
    "    \"\"\"\n",
    "        Calcula o número de neurônios para cada camada de uma rede neural, distribuídos aleatoriamente\n",
    "        entre a primeira e a última camada.\n",
    "        \n",
    "        Args:\n",
    "            num_neuronios_primeira (int): Número de neurônios na primeira camada.\n",
    "            num_neuronios_ultima (int): Número de neurônios na última camada.\n",
    "            num_camadas (int): Número total de camadas (incluindo a primeira e a última camada).\n",
    "\n",
    "        Returns:\n",
    "            lista: Uma lista com o número de neurônios para cada camada.\n",
    "    \"\"\"\n",
    "\n",
    "    # Calcula a diferença linear entre o número de neurônios da primeira e da última camada\n",
    "    diferenca_neuronios = (num_neuronios_ultima - num_neuronios_primeira) / (num_camadas - 1)\n",
    "    \n",
    "    # Calcula o número de neurônios para cada camada usando a função linear\n",
    "    neuronios_por_camada = [\n",
    "        int(num_neuronios_primeira + i * diferenca_neuronios) for i in range(num_camadas)\n",
    "    ]\n",
    "    \n",
    "    return neuronios_por_camada\n",
    "\n",
    "\n",
    "def get_model(n_inputs,\n",
    "              num_neuronios_primeira,\n",
    "              num_neuronios_ultima,\n",
    "              num_camadas,\n",
    "              alpha):\n",
    "    \"\"\"\n",
    "        Monta um modelo customizado para otimização de classificação binária\n",
    "        Args:\n",
    "            n_inputs (int): número de entradas\n",
    "            num_neuronios_primeira (int): número de neurônios da primeira camada dense\n",
    "            num_neuronios_ultima (int): número de neurônios da última camada dense\n",
    "            num_camadas (int):  número de camadas desejadas\n",
    "            alpha (float): taxa de aprendizado\n",
    "        Returns:\n",
    "            model (tf.model): o modelo compilado\n",
    "    \"\"\"\n",
    "    # acertando os ponteiros aleatórios - garantir reproducibilidade\n",
    "    tf.random.set_seed(42) # o número 42 é mágico, é a escolha preferida dos exemplos do sklearn.... ou pelo menos era\n",
    "\n",
    "    np.random.seed(42)\n",
    "\n",
    "    # instanciando o modelo\n",
    "    model = t_model.Sequential(name=\"modelo_turbinado_gdc\")\n",
    "\n",
    "    # primeiro passo: montar a camada de entrada\n",
    "    model.add(t_layers.Input(shape=(n_inputs, ), name='input'))\n",
    "\n",
    "    # calculando os neurônios de cada camada como uma função linear entre o numéro de neurônios de \n",
    "    # entrada e saída e número de camadas\n",
    "\n",
    "    neuronios_por_camada = calcular_neuronios(num_neuronios_primeira, \n",
    "                                              num_neuronios_ultima, \n",
    "                                              num_camadas)\n",
    "    \n",
    "    for i in range(num_camadas - 1):\n",
    "        model.add(t_layers.Dense(neuronios_por_camada[i], \n",
    "                                 activation='relu', \n",
    "                                 name=\"features_\" + str(i),\n",
    "                                 kernel_initializer=tf.keras.initializers.GlorotUniform(seed=42)))        \n",
    "    \n",
    "    model.add(t_layers.Dense(num_neuronios_ultima, \n",
    "                             activation='sigmoid', \n",
    "                             name=\"predictions\",\n",
    "                             kernel_initializer=tf.keras.initializers.GlorotUniform(seed=42)))\n",
    "        \n",
    "    model.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                  optimizer=tf.keras.optimizers.Adam(alpha))\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def simulate(n_inputs,\n",
    "             ann_epochs,\n",
    "             num_camadas,\n",
    "             num_neuronios_primeira,\n",
    "             X, \n",
    "             y, \n",
    "             X_test, \n",
    "             y_test,\n",
    "             alpha=0.001):\n",
    "    \"\"\"\n",
    "        Simulação dos parâmetros da rede neural\n",
    "        Args:\n",
    "            n_inputs (int): número de entradas\n",
    "            ann_epochs (int): épocas de treinamento\n",
    "            num_camadas (int): número de camadas da rede neural\n",
    "            num_neuronios_primeira (int): número de neurônios da primeira camada\n",
    "            X (ndarray): variável independente para treinamento\n",
    "            y (ndarray): variável dependente para treinamento\n",
    "            X_test (ndarray): variável independente para validação\n",
    "            y_test (ndarray): variável dependente para validação\n",
    "        Returns:\n",
    "            accuracy (float): a acurácia do treinamento\n",
    "    \"\"\"\n",
    "    num_neuronios_ultima = 1\n",
    "    model = get_model(n_inputs,\n",
    "                      num_neuronios_primeira,\n",
    "                      num_neuronios_ultima,\n",
    "                      num_camadas,\n",
    "                      alpha)\n",
    "    \n",
    "    model.fit(\n",
    "        X,\n",
    "        y,\n",
    "        epochs=ann_epochs, \n",
    "        verbose=0\n",
    "    )\n",
    "    p = model(X)\n",
    "    y_pred = (p.numpy() >= 0.5).astype(int)\n",
    "    acc_train= np.mean((y_pred==y)*100)\n",
    "    p = model(X_test)    \n",
    "    y_pred = (p.numpy() >= 0.5).astype(int)\n",
    "    acc_test = np.mean((y_pred==y_test)*100)\n",
    "    return acc_train, acc_test\n",
    "\n",
    "# definições do grid search\n",
    "\n",
    "print(len(X), len(X_val))\n",
    "\n",
    "ann_epochs = [50, 100, 150, 200, 250, 300]\n",
    "\n",
    "ann_num_neuronios_primeira = [10, 20, 30, 40, 50]\n",
    "\n",
    "ann_num_camadas = [2, 3, 4, 5]\n",
    "\n",
    "# Gerando as combinações\n",
    "parameters = gerar_combinacoes_hiperparametros(ann_epochs, \n",
    "                                               ann_num_neuronios_primeira, \n",
    "                                               ann_num_camadas)\n",
    "\n",
    "i = 1\n",
    "\n",
    "tabela = list()\n",
    "tabela_escolha = list()\n",
    "\n",
    "for parameter in parameters:\n",
    "    acc_train, acc_test = simulate(308,\n",
    "                                   parameter[0],\n",
    "                                   parameter[2],\n",
    "                                   parameter[1],\n",
    "                                   X_norm,\n",
    "                                   y,\n",
    "                                   X_val_norm,\n",
    "                                   y_val)\n",
    "\n",
    "    ann_epochs = parameter[0]\n",
    "    num_camadas = parameter[2]\n",
    "    num_neuronios_primeira = parameter[1]\n",
    "    \n",
    "    print(f\"{i} => Épocas = {ann_epochs}, Camadas = {num_camadas}, Neurônios da primeira camada = {num_neuronios_primeira}\")\n",
    "    print(f\"{i} => Treino: {acc_train:.2f}, Teste: {acc_test:.2f}\")\n",
    "    tabela.append([i, ann_epochs, num_camadas, num_neuronios_primeira, acc_train, acc_test])\n",
    "    if acc_test >= 80.0:\n",
    "        # atende ao requisito\n",
    "        tabela_escolha.append([i, ann_epochs, num_camadas, num_neuronios_primeira, acc_train, acc_test])\n",
    "        print(f\"Escolha do editor => Épocas = {ann_epochs},  Camadas = {num_camadas}, Neurônios da primeira camada = {num_neuronios_primeira}\")\n",
    "    i += 1\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados tabulados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testes de Redes Neurais, com variação de neurônios e camadas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   Teste |   Épocas |   Camadas |   Neurônios (1. C) |   $Acc_{treino}\\%$ |   $Acc_{teste}\\%$ |\n",
      "|--------:|---------:|----------:|-------------------:|-------------------:|------------------:|\n",
      "|       1 |       50 |         2 |                 10 |            94.1111 |           68.4375 |\n",
      "|       2 |       50 |         3 |                 10 |            96.2315 |           74.4583 |\n",
      "|       3 |       50 |         4 |                 10 |            94.1019 |           72.9792 |\n",
      "|       4 |       50 |         5 |                 10 |            97.5185 |           70.9167 |\n",
      "|       5 |       50 |         2 |                 20 |            95.8796 |           72.7083 |\n",
      "|       6 |       50 |         3 |                 20 |            96.6481 |           74.0625 |\n",
      "|       7 |       50 |         4 |                 20 |            98.0556 |           74.7708 |\n",
      "|       8 |       50 |         5 |                 20 |            98.1667 |           76.2917 |\n",
      "|       9 |       50 |         2 |                 30 |            96.5648 |           74.0208 |\n",
      "|      10 |       50 |         3 |                 30 |            97.713  |           75.4375 |\n",
      "|      11 |       50 |         4 |                 30 |            97.7685 |           75.3333 |\n",
      "|      12 |       50 |         5 |                 30 |            98.2963 |           75.1458 |\n",
      "|      13 |       50 |         2 |                 40 |            96.3056 |           74.7292 |\n",
      "|      14 |       50 |         3 |                 40 |            98.1019 |           82.2083 |\n",
      "|      15 |       50 |         4 |                 40 |            98.1574 |           76.6875 |\n",
      "|      16 |       50 |         5 |                 40 |            99.5463 |           73.5208 |\n",
      "|      17 |       50 |         2 |                 50 |            96.787  |           75      |\n",
      "|      18 |       50 |         3 |                 50 |            97.7778 |           77.6042 |\n",
      "|      19 |       50 |         4 |                 50 |            98.6204 |           78.1458 |\n",
      "|      20 |       50 |         5 |                 50 |            99.1111 |           78.9375 |\n",
      "|      21 |      100 |         2 |                 10 |            95.7963 |           70.9375 |\n",
      "|      22 |      100 |         3 |                 10 |            97.2407 |           77.9167 |\n",
      "|      23 |      100 |         4 |                 10 |            97.2407 |           73.6875 |\n",
      "|      24 |      100 |         5 |                 10 |            98.0093 |           68.2083 |\n",
      "|      25 |      100 |         2 |                 20 |            97.0278 |           74.4792 |\n",
      "|      26 |      100 |         3 |                 20 |            98.5648 |           75.875  |\n",
      "|      27 |      100 |         4 |                 20 |            99.4444 |           74.7292 |\n",
      "|      28 |      100 |         5 |                 20 |            99.6019 |           77.4792 |\n",
      "|      29 |      100 |         2 |                 30 |            97.3241 |           74.0417 |\n",
      "|      30 |      100 |         3 |                 30 |            99.3333 |           76.5    |\n",
      "|      31 |      100 |         4 |                 30 |            99.6852 |           76      |\n",
      "|      32 |      100 |         5 |                 30 |            99.6944 |           75.8125 |\n",
      "|      33 |      100 |         2 |                 40 |            97.7407 |           76.0417 |\n",
      "|      34 |      100 |         3 |                 40 |            99.7407 |           83.2917 |\n",
      "|      35 |      100 |         4 |                 40 |            99.8426 |           76.5833 |\n",
      "|      36 |      100 |         5 |                 40 |            99.4722 |           74.375  |\n",
      "|      37 |      100 |         2 |                 50 |            97.5556 |           75.0625 |\n",
      "|      38 |      100 |         3 |                 50 |            99.787  |           78.1042 |\n",
      "|      39 |      100 |         4 |                 50 |            99.7685 |           77.6667 |\n",
      "|      40 |      100 |         5 |                 50 |            99.6667 |           80.5    |\n",
      "|      41 |      150 |         2 |                 10 |            96.3704 |           70.4792 |\n",
      "|      42 |      150 |         3 |                 10 |            97.5926 |           81.125  |\n",
      "|      43 |      150 |         4 |                 10 |            97.6944 |           73.9583 |\n",
      "|      44 |      150 |         5 |                 10 |            98.5648 |           67.4583 |\n",
      "|      45 |      150 |         2 |                 20 |            97.3519 |           74.7708 |\n",
      "|      46 |      150 |         3 |                 20 |            99.1852 |           76.8333 |\n",
      "|      47 |      150 |         4 |                 20 |            99.7963 |           74.9167 |\n",
      "|      48 |      150 |         5 |                 20 |            99.4259 |           78.6875 |\n",
      "|      49 |      150 |         2 |                 30 |            97.9907 |           73.6875 |\n",
      "|      50 |      150 |         3 |                 30 |            99.787  |           77.0208 |\n",
      "|      51 |      150 |         4 |                 30 |            99.8519 |           75.75   |\n",
      "|      52 |      150 |         5 |                 30 |            99.6574 |           76.1458 |\n",
      "|      53 |      150 |         2 |                 40 |            98.3241 |           77.5208 |\n",
      "|      54 |      150 |         3 |                 40 |            99.7778 |           82.5833 |\n",
      "|      55 |      150 |         4 |                 40 |            99.6111 |           76.9583 |\n",
      "|      56 |      150 |         5 |                 40 |            99.7037 |           74.4792 |\n",
      "|      57 |      150 |         2 |                 50 |            98.4815 |           76.1458 |\n",
      "|      58 |      150 |         3 |                 50 |            99.8611 |           78.1875 |\n",
      "|      59 |      150 |         4 |                 50 |            99.8981 |           77.6458 |\n",
      "|      60 |      150 |         5 |                 50 |            99.7685 |           80.0625 |\n",
      "|      61 |      200 |         2 |                 10 |            96.4167 |           70.4167 |\n",
      "|      62 |      200 |         3 |                 10 |            97.6111 |           80.2917 |\n",
      "|      63 |      200 |         4 |                 10 |            98      |           74.125  |\n",
      "|      64 |      200 |         5 |                 10 |            98.6296 |           68.3333 |\n",
      "|      65 |      200 |         2 |                 20 |            97.787  |           75.1667 |\n",
      "|      66 |      200 |         3 |                 20 |            99.3426 |           77.5    |\n",
      "|      67 |      200 |         4 |                 20 |            99.8704 |           73.7917 |\n",
      "|      68 |      200 |         5 |                 20 |            99.6944 |           78.4792 |\n",
      "|      69 |      200 |         2 |                 30 |            98.2407 |           74.125  |\n",
      "|      70 |      200 |         3 |                 30 |            99.75   |           75.5208 |\n",
      "|      71 |      200 |         4 |                 30 |            99.5278 |           75.875  |\n",
      "|      72 |      200 |         5 |                 30 |            99.6111 |           76.5625 |\n",
      "|      73 |      200 |         2 |                 40 |            98.7778 |           77.875  |\n",
      "|      74 |      200 |         3 |                 40 |            99.8056 |           81.0625 |\n",
      "|      75 |      200 |         4 |                 40 |            99.8889 |           76.3542 |\n",
      "|      76 |      200 |         5 |                 40 |            99.8704 |           75.8958 |\n",
      "|      77 |      200 |         2 |                 50 |            99.0648 |           76.6667 |\n",
      "|      78 |      200 |         3 |                 50 |            99.8519 |           78.4167 |\n",
      "|      79 |      200 |         4 |                 50 |            99.8981 |           77.0625 |\n",
      "|      80 |      200 |         5 |                 50 |            99.8981 |           79.1042 |\n",
      "|      81 |      250 |         2 |                 10 |            96.537  |           70.8333 |\n",
      "|      82 |      250 |         3 |                 10 |            98.2315 |           80.3125 |\n",
      "|      83 |      250 |         4 |                 10 |            98.2963 |           73.5208 |\n",
      "|      84 |      250 |         5 |                 10 |            99.4815 |           67.6667 |\n",
      "|      85 |      250 |         2 |                 20 |            98.0185 |           75.6875 |\n",
      "|      86 |      250 |         3 |                 20 |            99.6667 |           76.9792 |\n",
      "|      87 |      250 |         4 |                 20 |            99.8519 |           73.1875 |\n",
      "|      88 |      250 |         5 |                 20 |            99.5648 |           77.8958 |\n",
      "|      89 |      250 |         2 |                 30 |            98.4722 |           75.2083 |\n",
      "|      90 |      250 |         3 |                 30 |            99.287  |           73.9167 |\n",
      "|      91 |      250 |         4 |                 30 |            99.7222 |           76.1458 |\n",
      "|      92 |      250 |         5 |                 30 |            99.8796 |           78.0417 |\n",
      "|      93 |      250 |         2 |                 40 |            99.1759 |           78.5    |\n",
      "|      94 |      250 |         3 |                 40 |            99.8148 |           78.8333 |\n",
      "|      95 |      250 |         4 |                 40 |            99.7222 |           75.6042 |\n",
      "|      96 |      250 |         5 |                 40 |            99.8611 |           75.6458 |\n",
      "|      97 |      250 |         2 |                 50 |            99.2037 |           77.0625 |\n",
      "|      98 |      250 |         3 |                 50 |            99.2963 |           77.0208 |\n",
      "|      99 |      250 |         4 |                 50 |            99.8796 |           76.8542 |\n",
      "|     100 |      250 |         5 |                 50 |            99.8981 |           81.3333 |\n",
      "|     101 |      300 |         2 |                 10 |            96.9722 |           70.625  |\n",
      "|     102 |      300 |         3 |                 10 |            98.75   |           79.6667 |\n",
      "|     103 |      300 |         4 |                 10 |            98.713  |           73.9375 |\n",
      "|     104 |      300 |         5 |                 10 |            99.3148 |           66.25   |\n",
      "|     105 |      300 |         2 |                 20 |            98.5185 |           76      |\n",
      "|     106 |      300 |         3 |                 20 |            99.6481 |           76.9167 |\n",
      "|     107 |      300 |         4 |                 20 |            99.7593 |           75.0417 |\n",
      "|     108 |      300 |         5 |                 20 |            99.8796 |           79.2083 |\n",
      "|     109 |      300 |         2 |                 30 |            98.8241 |           75.7917 |\n",
      "|     110 |      300 |         3 |                 30 |            99.2778 |           74.9167 |\n",
      "|     111 |      300 |         4 |                 30 |            99.8611 |           75.9792 |\n",
      "|     112 |      300 |         5 |                 30 |            99.8981 |           78.2083 |\n",
      "|     113 |      300 |         2 |                 40 |            99.5741 |           78.8542 |\n",
      "|     114 |      300 |         3 |                 40 |            99.8611 |           78.6875 |\n",
      "|     115 |      300 |         4 |                 40 |            99.8889 |           75.8542 |\n",
      "|     116 |      300 |         5 |                 40 |            99.8796 |           75.3333 |\n",
      "|     117 |      300 |         2 |                 50 |            99.787  |           77.7917 |\n",
      "|     118 |      300 |         3 |                 50 |            99.8981 |           78.0625 |\n",
      "|     119 |      300 |         4 |                 50 |            99.8981 |           77.3542 |\n",
      "|     120 |      300 |         5 |                 50 |            99.8981 |           82.3958 |\n"
     ]
    }
   ],
   "source": [
    "header = [\"Teste\", \"Épocas\", \"Camadas\", \"Neurônios (1. C)\", \"$Acc_{treino}\\%$\", \"$Acc_{teste}\\%$\"]\n",
    "print(tabulate(tabela,\n",
    "               headers=header,\n",
    "               tablefmt='pipe'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Redes neurais selecionadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   Teste |   Épocas |   Camadas |   Neurônios (1. C) |   $Acc_{treino}\\%$ |   $Acc_{teste}\\%$ |\n",
      "|--------:|---------:|----------:|-------------------:|-------------------:|------------------:|\n",
      "|      14 |       50 |         3 |                 40 |            98.1019 |           82.2083 |\n",
      "|      34 |      100 |         3 |                 40 |            99.7407 |           83.2917 |\n",
      "|      40 |      100 |         5 |                 50 |            99.6667 |           80.5    |\n",
      "|      42 |      150 |         3 |                 10 |            97.5926 |           81.125  |\n",
      "|      54 |      150 |         3 |                 40 |            99.7778 |           82.5833 |\n",
      "|      60 |      150 |         5 |                 50 |            99.7685 |           80.0625 |\n",
      "|      62 |      200 |         3 |                 10 |            97.6111 |           80.2917 |\n",
      "|      74 |      200 |         3 |                 40 |            99.8056 |           81.0625 |\n",
      "|      82 |      250 |         3 |                 10 |            98.2315 |           80.3125 |\n",
      "|     100 |      250 |         5 |                 50 |            99.8981 |           81.3333 |\n",
      "|     120 |      300 |         5 |                 50 |            99.8981 |           82.3958 |\n"
     ]
    }
   ],
   "source": [
    "header = [\"Teste\", \"Épocas\", \"Camadas\", \"Neurônios (1. C)\", \"$Acc_{treino}\\%$\", \"$Acc_{teste}\\%$\"]\n",
    "print(tabulate(tabela_escolha,\n",
    "               headers=header,\n",
    "               tablefmt='pipe'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distribuição de Neurônios para as redes neurais selecionadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Épocas = 50,  Camadas = 3, Neurônios da primeira camada = 40, Neurônios Por Camada = [40, 20, 1]\n",
      "Épocas = 100,  Camadas = 3, Neurônios da primeira camada = 40, Neurônios Por Camada = [40, 20, 1]\n",
      "Épocas = 100,  Camadas = 5, Neurônios da primeira camada = 50, Neurônios Por Camada = [50, 37, 25, 13, 1]\n",
      "Épocas = 150,  Camadas = 3, Neurônios da primeira camada = 10, Neurônios Por Camada = [10, 5, 1]\n",
      "Épocas = 150,  Camadas = 3, Neurônios da primeira camada = 40, Neurônios Por Camada = [40, 20, 1]\n",
      "Épocas = 150,  Camadas = 5, Neurônios da primeira camada = 50, Neurônios Por Camada = [50, 37, 25, 13, 1]\n",
      "Épocas = 200,  Camadas = 3, Neurônios da primeira camada = 10, Neurônios Por Camada = [10, 5, 1]\n",
      "Épocas = 200,  Camadas = 3, Neurônios da primeira camada = 40, Neurônios Por Camada = [40, 20, 1]\n",
      "Épocas = 250,  Camadas = 3, Neurônios da primeira camada = 10, Neurônios Por Camada = [10, 5, 1]\n",
      "Épocas = 250,  Camadas = 5, Neurônios da primeira camada = 50, Neurônios Por Camada = [50, 37, 25, 13, 1]\n",
      "Épocas = 300,  Camadas = 5, Neurônios da primeira camada = 50, Neurônios Por Camada = [50, 37, 25, 13, 1]\n"
     ]
    }
   ],
   "source": [
    "for escolha in tabela_escolha:\n",
    "    num_neuronios_primeira = escolha[3]\n",
    "    ann_epochs = escolha[1]\n",
    "    num_camadas = escolha[2]\n",
    "    neuronios = calcular_neuronios(num_neuronios_primeira, 1, num_camadas)\n",
    "\n",
    "    print(f\"Épocas = {ann_epochs},  Camadas = {num_camadas}, Neurônios da primeira camada = {num_neuronios_primeira}, Neurônios Por Camada = {neuronios}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "dl_toc_settings": {
   "rndtag": "89367"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
